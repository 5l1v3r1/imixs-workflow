#Database Schema

The Imixs-Workflow Engine supports a generic database schema which allows to store all workflow data in a flexible way. The Imixs-Workflow Engine is based on the Java Persistence API (JPA) which makes it independent form a database vendor. For that reason any database system can be used for the deployment.
 
##Deployment
To deploy the Imixs-Workflow Engine into a JEE Application server it is necessary to provide  a JEE datasource. A JEE datasource defines the connection form the application to a relational database on a database server. The only configuration file which is necessary to define the database connection is the persistence.xml. This is a standard descriptor which should be placed into your application.
 
	<?xml version="1.0" encoding="UTF-8"?>
	<persistence version="1.0" xmlns="http://java.sun.com/xml/ns/persistence">
		<persistence-unit name="org.imixs.workflow.jee.jpa" transaction-type="JTA">	
			<provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>	
			<jta-data-source>jdbc/workflow-db</jta-data-source>
			<jar-file>lib/imixs-workflow-engine-${org.imixs.workflow.version}.jar</jar-file>
			<properties>
				<property name="eclipselink.target-database" value="Auto" />
				<property name="eclipselink.ddl-generation" value="create-tables" />
				<property name="eclipselink.deploy-on-startup" value="true" />
			</properties>				
		</persistence-unit>
	</persistence>
 
The section persistence-unit specifies the data objects to be stored into the database. The unit name is defined by the Imixs-Workflow Engine and should not be changed. The jta-data-source defines the name of the datasource to be used by the Imixs-Workflow Engine to store data into the database.
 
##The JPA Classes and Tables
The database schema used by the Imixs-Workflow Engine is defined by a set of JPA classes which are part of the package org.imixs.workflow.jee.jpa. During the deployment phase these classes are mapped automatically to a database schema from a database and the corresponding data tables will be created by the JPA implementation. For each of the following Entity classes a table is generated:
 
 
   * Entity
   * EntityData
   * EntityIndex
   * TextItem
   * IntegerItem
   * DoubleItem
   * CallendarItem
   * ReadAccessEntity
   * WriteAccessEntity
 
Each data object managed by the Imixs-Workflow Engine is mapped to an instance of the Entity Object which contains a unique ID to identify the Entity. The Entity holds also access informations which describes if the entity can be read or modified from individual users. So the schema provides a dynamic access control list (ACL) for each Entity Object.  
The data of a process instance will be stored into the EntityData Object which is mapped to a binary large object (blob) inside a database. This enables an application to store any kind of data independent from the structure of the database. To access data using the JPQL select statements 4 additional data type specific objects are defined:
  
  * TextItem
  * IntegerItem
  * DoubleItem
  * CalendarItem
  
The Imixs-Workflow Engine maps any data stored by the EntiyData Object to one of these specific data types if a corresponding IndexEntity is defined. As a result the data objects can be selected using a JPA query language. Read more about the usage of JPQL the section [JPQL](../engine/queries.html).
  
  

##Performance
In large databases with a lot of workitems there can occur a performance issue which  slows down the response time of an application in some situations. The reason for this issue is the default database schema. This schema is generated by the application server the first time the Imixs Workflow engine where deployed. 
 
This is a typical example with more than one JOIN clauses that can result in a slow-down of the response time :

	SELECT DISTINCT environment FROM Entity AS environment
	 JOIN environment.textItems as n 
	 JOIN environment.textItems as v
	 JOIN environment.textItems as c
	 AND environment.type = 'WorkflowEnvironmentEntity'
	 AND n.itemName = 'txtname' AND n.itemValue = 'environment.profile'
	 AND v.itemName = '$modelversion' AND v.itemValue = 'public-de-standard-0.0.1'
	 AND c.itemName = 'case'
	 ORDER BY c.itemValue 


To fix this problem it is necessary to add additional indices to the database tables generated by the  application servers OR-Mapper. This can be done with the database tools provided by your database vendor. For MySQL use the "MySQL Administrator Tool".
 
The most important tables where an additional index should be added are the database tables
 "ENTITY", "TEXTITEM", "INTEGERITEM" and "CALENDARITEM". This tables typical holds the most data rows. Useful default indices to the columns "TYPE", "ITEMVALUE" and "ITEMNAME"
 are not created per default.  So to add the necessary index manually you run call the following SQL commands: 
 
	ALTER TABLE `ENTITY` ADD INDEX `index1`(`CREATED`,`MODIFIED`,`TYPE`,`VERSION`);
	ALTER TABLE `TEXTITEM` ADD INDEX `index1`(`ITEMNAME`, `ITEMVALUE`);
	ALTER TABLE `INTEGERITEM` ADD INDEX `index1`(`ITEMNAME`, `ITEMVALUE`);
	ALTER TABLE `CALENDARITEM` ADD INDEX `index1`(`ITEMNAME`, `ITEMVALUE`);
	ALTER TABLE `DOUBLEITEM` ADD INDEX `index1`(`ITEMNAME`, `ITEMVALUE`);
	ALTER TABLE `READACCESS` ADD INDEX `index1`(`VALUE`);
	ALTER TABLE `WRITEACCESS` ADD INDEX `index1`(`VALUE`);

After adding the index the response time should be nice again.

For PostgreSQL use the following statement:

	CREATE INDEX index_entity1 ON entity USING btree(created, modified, type , version);
	CREATE INDEX index_textitem1 ON textitem USING btree(itemname,itemvalue);
	CREATE INDEX index_integeritem1 ON integeritem USING btree(itemname,itemvalue);
	CREATE INDEX index_calendaritem1 ON calendaritem USING btree(itemname,itemvalue);
	CREATE INDEX index_doubleitem1 ON doubleitem USING btree(itemname,itemvalue);
	CREATE INDEX index_read1 ON readaccess USING btree(value);
	CREATE INDEX index_write1 ON writeaccess USING btree(value);
 
  
<strong>Note:</strong> It can be necessary to add also indices to other tables/columns created by the OR-Mapper. To find out useful indices contact your database administrator or use Query analyser tools provided by your database vendor.
         
         
##Foreign key constraint failures  
In some situations a SQL Exception forced by a foreign key constraint failure can occur
during complex transactions. In this case the wrong a cascading type of the auto generated
 foreign keys can be the reason.  Use the following sql statements to alter the foreign key from 'ON DELETE RESTRICT' to  'ON DELETE CASCADE' to fix the problem. Make sure that you stop GlassFish before changing the keys.
 
###MySQL
 
	ALTER TABLE `ENTITY_WRITEACCESS` 
	DROP FOREIGN KEY `FK_ENTITY_WRITEACCESS_writeAccessList_ID`;
	ALTER TABLE `ENTITY_WRITEACCESS` 
	ADD CONSTRAINT `FK_ENTITY_WRITEACCESS_writeAccessList_ID`
	  FOREIGN KEY (`writeAccessList_ID`)
	  REFERENCES `WRITEACCESS` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT;
	  
	ALTER TABLE `ENTITY_READACCESS` 
	DROP FOREIGN KEY `FK_ENTITY_READACCESS_readAccessList_ID`;
	ALTER TABLE `ENTITY_READACCESS` 
	ADD CONSTRAINT `FK_ENTITY_READACCESS_readAccessList_ID`
	  FOREIGN KEY (`readAccessList_ID`)
	  REFERENCES `READACCESS` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT;
	
	ALTER TABLE `ENTITY_TEXTITEM` 
	DROP FOREIGN KEY `FK_ENTITY_TEXTITEM_textItems_ID`;
	ALTER TABLE `ENTITY_TEXTITEM` 
	ADD CONSTRAINT `FK_ENTITY_TEXTITEM_textItems_ID`
	  FOREIGN KEY (`textItems_ID`)
	  REFERENCES `TEXTITEM` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT; 
	  
	ALTER TABLE `ENTITY_INTEGERITEM` 
	DROP FOREIGN KEY `FK_ENTITY_INTEGERITEM_integerItems_ID`;
	ALTER TABLE `ENTITY_INTEGERITEM` 
	ADD CONSTRAINT `FK_ENTITY_INTEGERITEM_integerItems_ID`
	  FOREIGN KEY (`integerItems_ID`)
	  REFERENCES `INTEGERITEM` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT; 
	  
	ALTER TABLE `ENTITY_DOUBLEITEM` 
	DROP FOREIGN KEY `FK_ENTITY_DOUBLEITEM_doubleItems_ID`;
	ALTER TABLE `ENTITY_DOUBLEITEM` 
	ADD CONSTRAINT `FK_ENTITY_DOUBLEITEM_doubleItems_ID`
	  FOREIGN KEY (`doubleItems_ID`)
	  REFERENCES `DOUBLEITEM` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT; 
	  
	ALTER TABLE `ENTITY_CALENDARITEM` 
	DROP FOREIGN KEY `FK_ENTITY_CALENDARITEM_calendarItems_ID`;
	ALTER TABLE `ENTITY_CALENDARITEM` 
	ADD CONSTRAINT `FK_ENTITY_CALENDARITEM_calendarItems_ID`
	  FOREIGN KEY (`calendarItems_ID`)
	  REFERENCES `CALENDARITEM` (`ID`)
	  ON DELETE CASCADE
	  ON UPDATE RESTRICT; 

###PostgreSQL
 
	ALTER TABLE ENTITY_TEXTITEM
	DROP constraint FK_ENTITY_TEXTITEM_textItems_ID,
	ADD CONSTRAINT FK_ENTITY_TEXTITEM_textItems_ID
	  FOREIGN KEY (textItems_ID)
	  REFERENCES TEXTITEM (ID)
	  ON DELETE CASCADE; 
	
	ALTER TABLE ENTITY_INTEGERITEM
	DROP constraint FK_ENTITY_INTEGERITEM_integerItems_ID,
	ADD CONSTRAINT FK_ENTITY_INTEGERITEM_integerItems_ID
	  FOREIGN KEY (integerItems_ID)
	  REFERENCES INTEGERITEM (ID)
	  ON DELETE CASCADE;
	
	ALTER TABLE ENTITY_DOUBLEITEM
	DROP constraint FK_ENTITY_DOUBLEITEM_doubleItems_ID,
	ADD CONSTRAINT FK_ENTITY_DOUBLEITEM_doubleItems_ID
	  FOREIGN KEY (doubleItems_ID)
	  REFERENCES DOUBLEITEM (ID)
	  ON DELETE CASCADE;
	
	ALTER TABLE ENTITY_CALENDARITEM
	DROP constraint FK_ENTITY_CALENDARITEM_calendarItems_ID,
	ADD CONSTRAINT FK_ENTITY_CALENDARITEM_calendarItems_ID
	  FOREIGN KEY (calendarItems_ID)
	  REFERENCES CALENDARITEM (ID)
	  ON DELETE CASCADE;
	
	ALTER TABLE ENTITY_WRITEACCESS
	DROP constraint FK_ENTITY_WRITEACCESS_writeAccessList_ID,
	ADD CONSTRAINT FK_ENTITY_WRITEACCESS_writeAccessList_ID
	  FOREIGN KEY (writeAccessList_ID)
	  REFERENCES WRITEACCESS (ID)
	  ON DELETE CASCADE;
	
	ALTER TABLE ENTITY_READACCESS
	DROP constraint FK_ENTITY_READACCESS_readAccessList_ID,
	ADD CONSTRAINT FK_ENTITY_READACCESS_readAccessList_ID
	  FOREIGN KEY (readAccessList_ID)
	  REFERENCES READACCESS (ID)
	  ON DELETE CASCADE;


